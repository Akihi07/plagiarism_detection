{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 剽窃检测模型\n",
    "\n",
    "创建了训练和测试数据后，可以定义和训练模型了。在此 notebook 中，你的目标是训练一个二元分类模型，它会根据你提供的特征学习将答案文件标为剽窃文件或非剽窃文件。\n",
    "\n",
    "此任务将分成以下几个步骤：\n",
    "\n",
    "* 将数据上传到 S3。\n",
    "* 定义一个二元分类模型和训练脚本。\n",
    "* 训练和部署模型。\n",
    "* 评估部署的分类器并回答关于所采用方法的一些问题。\n",
    "\n",
    "要完成此 notebook，你需要完成此 notebook 中的所有练习并回答所有问题。\n",
    "> 所有任务将清晰地标为**练习**，问题都标为**问题**。\n",
    "\n",
    "你可以尝试不同的分类模型，并选择一个在此数据集上效果最佳的模型。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将数据上传到 S3\n",
    "\n",
    "在上个 notebook 中，你应该使用给定剽窃/非剽窃文本数据语料库的特征和类别标签创建了两个文件：`training.csv` 和 `test.csv` 文件。\n",
    "\n",
    ">以下单元格将加载一些 AWS SageMaker 库并创建一个默认存储桶。创建此存储桶后，你可以将本地存储的数据上传到 S3。\n",
    "\n",
    "将训练和测试 `.csv` 特征文件保存到本地。你可以在 SageMaker 中运行第二个 notebook“2_Plagiarism_Feature_Engineering”，或者使用 Jupyter Lab 中的上传图标手动将文件上传到此 notebook。然后，你可以使用 `sagemaker_session.upload_data` 将本地文件上传到 S3，并直接指向训练数据的存储位置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "# session and role\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# create an S3 bucket\n",
    "bucket = sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 练习：将训练数据上传到 S3\n",
    "\n",
    "指定在其中保存了 `train.csv` 文件的 `data_dir`。指定一个描述性 `prefix`，指出数据将上传到默认 S3 存储桶的什么位置。最后，通过调用 `sagemaker_session.upload_data` 并传入必要的参数，创建一个指向训练数据的指针。建议参考 [Session 文档](https://sagemaker.readthedocs.io/en/stable/session.html#sagemaker.session.Session.upload_data)或之前的 SageMaker 代码示例。\n",
    "\n",
    "你需要上传整个目录。之后，训练脚本将仅访问 `train.csv` 文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should be the name of directory you created to save your features data\n",
    "data_dir = 'plagiarism_data'\n",
    "\n",
    "# set prefix, a descriptive name for a directory  \n",
    "prefix = 'sagemaker/plagiarism_detect'\n",
    "\n",
    "# upload all data to S3\n",
    "input_data = sagemaker_session.upload_data(path = data_dir,bucket = bucket,key_prefix = prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试单元格\n",
    "\n",
    "测试数据是否已成功上传。以下单元格将输出 S3 存储桶中的内容，如果为空，将抛出错误。你应该看到 `data_dir` 的内容，或许还有一些检查点。如果你看到其中列出了任何其他文件，那么你也许有一些旧的模型文件，你可以通过 S3 控制台删除这些旧文件（不过多余的文件应该不会影响在此 notebook 中开发的模型的性能）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moon-data/.ipynb_checkpoints/train-checkpoint.csv\n",
      "moon-data/sagemaker-pytorch-2020-07-30-07-22-10-950/debug-output/training_job_end.ts\n",
      "moon-data/sagemaker-pytorch-2020-07-30-07-22-10-950/output/model.tar.gz\n",
      "moon-data/sagemaker-pytorch-2020-07-30-07-26-25-698/debug-output/training_job_end.ts\n",
      "moon-data/sagemaker-pytorch-2020-07-30-07-26-25-698/output/model.tar.gz\n",
      "moon-data/train.csv\n",
      "sagemaker-pytorch-2020-07-30-06-53-33-057/source/sourcedir.tar.gz\n",
      "sagemaker-pytorch-2020-07-30-06-59-13-744/source/sourcedir.tar.gz\n",
      "sagemaker-pytorch-2020-07-30-07-17-38-287/source/sourcedir.tar.gz\n",
      "sagemaker-pytorch-2020-07-30-07-22-10-950/source/sourcedir.tar.gz\n",
      "sagemaker-pytorch-2020-07-30-07-26-25-698/source/sourcedir.tar.gz\n",
      "sagemaker-pytorch-2020-07-30-07-32-42-757/source/sourcedir.tar.gz\n",
      "sagemaker-pytorch-2020-07-30-07-38-14-869/source/sourcedir.tar.gz\n",
      "sagemaker-pytorch-2020-07-30-07-43-36-727/source/sourcedir.tar.gz\n",
      "sagemaker-pytorch-2020-07-30-07-48-26-758/sourcedir.tar.gz\n",
      "sagemaker-pytorch-2020-07-30-07-59-28-895/source/sourcedir.tar.gz\n",
      "sagemaker-pytorch-2020-07-30-08-04-58-128/sourcedir.tar.gz\n",
      "sagemaker-pytorch-2020-07-30-08-26-11-456/source/sourcedir.tar.gz\n",
      "sagemaker-pytorch-2020-07-30-08-31-25-029/sourcedir.tar.gz\n",
      "sagemaker/moon-data/sagemaker-pytorch-2020-07-28-07-32-27-422/debug-output/training_job_end.ts\n",
      "sagemaker/moon-data/sagemaker-pytorch-2020-07-28-07-32-27-422/output/model.tar.gz\n",
      "sagemaker/moon-data/train.csv\n",
      "sagemaker/plagiarism_detect/sagemaker-pytorch-2020-07-30-07-38-14-869/debug-output/training_job_end.ts\n",
      "sagemaker/plagiarism_detect/sagemaker-pytorch-2020-07-30-07-38-14-869/output/model.tar.gz\n",
      "sagemaker/plagiarism_detect/sagemaker-pytorch-2020-07-30-07-43-36-727/debug-output/training_job_end.ts\n",
      "sagemaker/plagiarism_detect/sagemaker-pytorch-2020-07-30-07-43-36-727/output/model.tar.gz\n",
      "sagemaker/plagiarism_detect/sagemaker-pytorch-2020-07-30-07-59-28-895/debug-output/training_job_end.ts\n",
      "sagemaker/plagiarism_detect/sagemaker-pytorch-2020-07-30-07-59-28-895/output/model.tar.gz\n",
      "sagemaker/plagiarism_detect/sagemaker-pytorch-2020-07-30-08-26-11-456/debug-output/training_job_end.ts\n",
      "sagemaker/plagiarism_detect/sagemaker-pytorch-2020-07-30-08-26-11-456/output/model.tar.gz\n",
      "sagemaker/plagiarism_detect/test.csv\n",
      "sagemaker/plagiarism_detect/train.csv\n",
      "sagemaker/sentiment_rnn/train.csv\n",
      "sagemaker/sentiment_rnn/word_dict.pkl\n",
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "# confirm that data is in S3 bucket\n",
    "empty_check = []\n",
    "for obj in boto3.resource('s3').Bucket(bucket).objects.all():\n",
    "    empty_check.append(obj.key)\n",
    "    print(obj.key)\n",
    "\n",
    "assert len(empty_check) !=0, 'S3 bucket is empty.'\n",
    "print('Test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 建模\n",
    "\n",
    "上传训练数据后，下面定义并训练模型。\n",
    "\n",
    "你可以决定创建什么类型的模型。对于二元分类任务，你可以选择采用以下三种方法之一：\n",
    "* 使用内置的分类算法，例如 LinearLearner。\n",
    "* 定义自定义 Scikit-learn 分类器，可以在[此处](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html)找到各个模型的比较情况。\n",
    "* 定义自定义 PyTorch 神经网络分类器。\n",
    "\n",
    "你需要测试各种模型并选择最佳模型。我们将根据最终模型的准确率对你的项目打分。\n",
    " \n",
    "---\n",
    "\n",
    "## 练习：完成训练脚本\n",
    "\n",
    "为了实现自定义分类器，你需要完成 `train.py` 脚本。我们提供了文件夹 `source_sklearn` 和 `source_pytorch`，其中分别包含自定义 Scikit-learn 模型和 PyTorch 模型的起始代码。每个目录都有一个 `train.py` 训练脚本。要完成此项目，**你只需完成其中一个脚本**，即负责训练最终模型的脚本。\n",
    "\n",
    "典型的训练脚本会：\n",
    "* 从指定的目录加载训练数据\n",
    "* 解析所有的训练和模型超参数（例如神经网络中的节点数，训练周期，等等）\n",
    "* 实例化你设计的模型，并采用指定的超参数\n",
    "* 训练该模型\n",
    "* 最后，保存模型，以便之后托管/部署模型\n",
    "\n",
    "### 定义和训练模型\n",
    "我们已经提供了大部分训练脚本。几乎所有任务都位于 `if __name__ == '__main__':` 部分。为了完成 `train.py` 文件，你需要：\n",
    "1. 导入所需的任何额外库\n",
    "2. 使用 `parser.add_argument` 定义任何其他模型训练超参数\n",
    "2. 在 `if __name__ == '__main__':` 部分定义模型\n",
    "3. 在此部分训练模型\n",
    "\n",
    "你可以在下面使用 `!pygmentize` 显示现有的 `train.py` 文件。请通读代码，所有任务都标有 `TODO` 注释。 \n",
    "\n",
    "**注意：如果你选择创建自定义 PyTorch 模型，需要在 `model.py` 文件中定义模型**，并且我们提供了 `predict.py` 文件。如果你选择使用 Scikit-learn，则只需 `train.py` 文件；你可以从 `sklearn` 库中导入一个分类器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m# torch imports\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mfunctional\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mF\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnn\u001b[39;49;00m\r\n",
      "\r\n",
      "\r\n",
      "\u001b[37m## TODO: Complete this classifier\u001b[39;49;00m\r\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mBinaryClassifier\u001b[39;49;00m(nn.Module):\r\n",
      "    \u001b[33m\"\"\"\u001b[39;49;00m\r\n",
      "\u001b[33m    Define a neural network that performs binary classification.\u001b[39;49;00m\r\n",
      "\u001b[33m    The network should accept your number of features as input, and produce \u001b[39;49;00m\r\n",
      "\u001b[33m    a single sigmoid value, that can be rounded to a label: 0 or 1, as output.\u001b[39;49;00m\r\n",
      "\u001b[33m    \u001b[39;49;00m\r\n",
      "\u001b[33m    Notes on training:\u001b[39;49;00m\r\n",
      "\u001b[33m    To train a binary classifier in PyTorch, use BCELoss.\u001b[39;49;00m\r\n",
      "\u001b[33m    BCELoss is binary cross entropy loss, documentation: https://pytorch.org/docs/stable/nn.html#torch.nn.BCELoss\u001b[39;49;00m\r\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\r\n",
      "\r\n",
      "    \u001b[37m## TODO: Define the init function, the input params are required (for loading code in train.py to work)\u001b[39;49;00m\r\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__init__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, input_features, hidden_dim, output_dim):\r\n",
      "        \u001b[33m\"\"\"\u001b[39;49;00m\r\n",
      "\u001b[33m        Initialize the model by setting up linear layers.\u001b[39;49;00m\r\n",
      "\u001b[33m        Use the input parameters to help define the layers of your model.\u001b[39;49;00m\r\n",
      "\u001b[33m        :param input_features: the number of input features in your training/test data\u001b[39;49;00m\r\n",
      "\u001b[33m        :param hidden_dim: helps define the number of nodes in the hidden layer(s)\u001b[39;49;00m\r\n",
      "\u001b[33m        :param output_dim: the number of outputs you want to produce\u001b[39;49;00m\r\n",
      "\u001b[33m        \"\"\"\u001b[39;49;00m\r\n",
      "        \u001b[36msuper\u001b[39;49;00m(BinaryClassifier, \u001b[36mself\u001b[39;49;00m).\u001b[32m__init__\u001b[39;49;00m()\r\n",
      "\r\n",
      "        \u001b[37m# define any initial layers, here\u001b[39;49;00m\r\n",
      "        \u001b[36mself\u001b[39;49;00m.fc1 = nn.Linear(input_features,hidden_dim)\r\n",
      "        \u001b[36mself\u001b[39;49;00m.fc2 = nn.Linear(hidden_dim,output_dim)\r\n",
      "        \u001b[36mself\u001b[39;49;00m.dropout = nn.Dropout(\u001b[34m0.3\u001b[39;49;00m)\r\n",
      "        \r\n",
      "        \u001b[36mself\u001b[39;49;00m.sig = nn.Sigmoid()\r\n",
      "\r\n",
      "    \r\n",
      "    \u001b[37m## TODO: Define the feedforward behavior of the network\u001b[39;49;00m\r\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mforward\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, x):\r\n",
      "        \u001b[33m\"\"\"\u001b[39;49;00m\r\n",
      "\u001b[33m        Perform a forward pass of our model on input features, x.\u001b[39;49;00m\r\n",
      "\u001b[33m        :param x: A batch of input features of size (batch_size, input_features)\u001b[39;49;00m\r\n",
      "\u001b[33m        :return: A single, sigmoid-activated value as output\u001b[39;49;00m\r\n",
      "\u001b[33m        \"\"\"\u001b[39;49;00m\r\n",
      "        \r\n",
      "        \u001b[37m# define the feedforward behavior\u001b[39;49;00m\r\n",
      "        out = F.relu(\u001b[36mself\u001b[39;49;00m.fc1(x))\r\n",
      "        \u001b[37m#print(\"-->{}\".format(out.size()))\u001b[39;49;00m\r\n",
      "        out = \u001b[36mself\u001b[39;49;00m.dropout(out)\r\n",
      "        \u001b[37m#print(\"-->{}\".format(out.size()))\u001b[39;49;00m\r\n",
      "        out = \u001b[36mself\u001b[39;49;00m.fc2(out)\r\n",
      "        \r\n",
      "        \u001b[34mreturn\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.sig(out)\r\n",
      "    \r\n"
     ]
    }
   ],
   "source": [
    "# directory can be changed to: source_sklearn or source_pytorch\n",
    "!pygmentize source_pytorch/model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提供的代码\n",
    "\n",
    "如果你阅读了上述代码，就会发现起始代码包含：\n",
    "* 模型加载 (`model_fn`) 和保存代码\n",
    "* 获取 SageMaker 的默认超参数\n",
    "* 按照名称 `train.csv` 加载训练数据，并提取特征和标签 `train_x` 和 `train_y`\n",
    "\n",
    "如果你想详细了解如何通过 [joblib for sklearn](https://scikit-learn.org/stable/modules/model_persistence.html) 或 [torch.save](https://pytorch.org/tutorials/beginner/saving_loading_models.html) 保存模型，请点击提供的链接。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 创建评估器\n",
    "\n",
    "在 SageMaker 中构建自定义模型时，必须指定入口点。入口点是一个 Python 文件，当模型被训练时，该文件将执行，即你在上面指定的 `train.py` 函数。要在 SageMaker 中运行自定义训练脚本，你需要构建评估器并指定相应的构造函数参数：\n",
    "\n",
    "* **entry_point**：SageMaker 训练模型和预测时运行的 Python 脚本的路径。\n",
    "* **source_dir**：训练脚本目录 `source_sklearn` 或 `source_pytorch` 的路径。\n",
    "* **entry_point**：SageMaker 训练模型和预测时运行的 Python 脚本的路径。\n",
    "* **source_dir**：训练脚本目录 `train_sklearn` 或 `train_pytorch` 的路径。\n",
    "* **entry_point**：SageMaker 训练模型时运行的 Python 脚本的路径。\n",
    "* **source_dir**：训练脚本目录 `train_sklearn` 或 `train_pytorch` 的路径。\n",
    "* **role**：角色 ARN，在上面已指定。\n",
    "* **train_instance_count**：训练实例的数量（应该保留为 1）。\n",
    "* **train_instance_type**：SageMaker 训练实例的类型。注意，因为 Scikit-learn 不提供 GPU 训练原生支持，所以 Sagemaker Scikit-learn 目前不支持在 GPU 实例上训练模型。\n",
    "* **sagemaker_session**：在 Sagemaker 中训练时使用的会话。\n",
    "* **hyperparameters**（可选）：作为超参数传递给训练函数的字典 `{'name':value, ..}`。\n",
    "\n",
    "注意：对于 PyTorch 模型，还有一个可选参数 **framework_version**，你可以将其设为最新的 PyTorch 版本 `1.0`。\n",
    "\n",
    "## 练习：定义 Scikit-learn 或 PyTorch 评估器\n",
    "\n",
    "你可以使用以下命令之一导入一个评估器：\n",
    "```\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "```\n",
    "```\n",
    "from sagemaker.pytorch import PyTorch\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your import and estimator code, here\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "# specify out put path\n",
    "output_path = 's3://{}/{}'.format(bucket,prefix)\n",
    "\n",
    "# difine the estimator\n",
    "estimator = PyTorch(entry_point = 'train.py',\n",
    "                    source_dir = 'source_pytorch',\n",
    "                    framework_version = '1.0',\n",
    "                    role = role,\n",
    "                    output_path = output_path,\n",
    "                    sagemaker_session = sagemaker_session,\n",
    "                    train_instance_count = 1,\n",
    "                    train_instance_type = 'ml.p2.xlarge',\n",
    "                    hyperparameters = {\n",
    "                        'input_features':3,\n",
    "                        'hidden_dim':30,\n",
    "                        'output_dim':1,\n",
    "                        'epochs':80\n",
    "                    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 练习：训练评估器\n",
    "\n",
    "使用在 S3 中存储的训练数据训练评估器。代码应该创建一个训练作业，你可以在 SageMaker 控制台中监控该作业。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-30 08:53:45 Starting - Starting the training job...\n",
      "2020-07-30 08:53:48 Starting - Launching requested ML instances.........\n",
      "2020-07-30 08:55:31 Starting - Preparing the instances for training.........\n",
      "2020-07-30 08:56:58 Downloading - Downloading input data......\n",
      "2020-07-30 08:58:15 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-07-30 08:58:16,368 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-07-30 08:58:16,394 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-07-30 08:58:19,489 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-07-30 08:58:19,768 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-07-30 08:58:19,768 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-07-30 08:58:19,768 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-07-30 08:58:19,768 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m pip install -U . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: train\n",
      "  Running setup.py bdist_wheel for train: started\u001b[0m\n",
      "\u001b[34m  Running setup.py bdist_wheel for train: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-39n7o9m5/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[34mSuccessfully built train\u001b[0m\n",
      "\u001b[34mInstalling collected packages: train\u001b[0m\n",
      "\u001b[34mSuccessfully installed train-1.0.0\u001b[0m\n",
      "\u001b[34mYou are using pip version 18.1, however version 20.2 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-07-30 08:58:21,743 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"hidden_dim\": 30,\n",
      "        \"input_features\": 3,\n",
      "        \"epochs\": 80,\n",
      "        \"output_dim\": 1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-pytorch-2020-07-30-08-53-45-384\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-235294566476/sagemaker-pytorch-2020-07-30-08-53-45-384/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":80,\"hidden_dim\":30,\"input_features\":3,\"output_dim\":1}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-235294566476/sagemaker-pytorch-2020-07-30-08-53-45-384/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":80,\"hidden_dim\":30,\"input_features\":3,\"output_dim\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-pytorch-2020-07-30-08-53-45-384\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-235294566476/sagemaker-pytorch-2020-07-30-08-53-45-384/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"80\",\"--hidden_dim\",\"30\",\"--input_features\",\"3\",\"--output_dim\",\"1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_HIDDEN_DIM=30\u001b[0m\n",
      "\u001b[34mSM_HP_INPUT_FEATURES=3\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=80\u001b[0m\n",
      "\u001b[34mSM_HP_OUTPUT_DIM=1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m train --epochs 80 --hidden_dim 30 --input_features 3 --output_dim 1\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mUsing device cuda.\u001b[0m\n",
      "\u001b[34mGet train data loader.\u001b[0m\n",
      "\u001b[34mEpoch: 1, Loss: 0.7462613838059562\u001b[0m\n",
      "\u001b[34mEpoch: 2, Loss: 0.7268036944525582\u001b[0m\n",
      "\u001b[34mEpoch: 3, Loss: 0.72186450447355\u001b[0m\n",
      "\u001b[34mEpoch: 4, Loss: 0.6889302815709796\u001b[0m\n",
      "\u001b[34mEpoch: 5, Loss: 0.6940030370439801\u001b[0m\n",
      "\u001b[34mEpoch: 6, Loss: 0.6977735928126744\u001b[0m\n",
      "\u001b[34mEpoch: 7, Loss: 0.6676248567444938\u001b[0m\n",
      "\u001b[34mEpoch: 8, Loss: 0.6744269217763629\u001b[0m\n",
      "\u001b[34mEpoch: 9, Loss: 0.6410408105169024\u001b[0m\n",
      "\u001b[34mEpoch: 10, Loss: 0.6429633072444371\u001b[0m\n",
      "\u001b[34mEpoch: 11, Loss: 0.6514722193990435\u001b[0m\n",
      "\u001b[34mEpoch: 12, Loss: 0.6594622390610831\u001b[0m\n",
      "\u001b[34mEpoch: 13, Loss: 0.6374986938067845\u001b[0m\n",
      "\u001b[34mEpoch: 14, Loss: 0.6167981624603271\u001b[0m\n",
      "\u001b[34mEpoch: 15, Loss: 0.6152922425951276\u001b[0m\n",
      "\u001b[34mEpoch: 16, Loss: 0.6321824363299778\u001b[0m\n",
      "\u001b[34mEpoch: 17, Loss: 0.6219157065664019\u001b[0m\n",
      "\u001b[34mEpoch: 18, Loss: 0.6266651494162423\u001b[0m\n",
      "\u001b[34mEpoch: 19, Loss: 0.6121174607958112\u001b[0m\n",
      "\u001b[34mEpoch: 20, Loss: 0.6266994050570897\u001b[0m\n",
      "\u001b[34mEpoch: 21, Loss: 0.6076016766684396\u001b[0m\n",
      "\u001b[34mEpoch: 22, Loss: 0.6249519160815648\u001b[0m\n",
      "\u001b[34mEpoch: 23, Loss: 0.5933563368661063\u001b[0m\n",
      "\u001b[34mEpoch: 24, Loss: 0.6016426597322736\u001b[0m\n",
      "\u001b[34mEpoch: 25, Loss: 0.5917130964142936\u001b[0m\n",
      "\u001b[34mEpoch: 26, Loss: 0.6004733783858163\u001b[0m\n",
      "\u001b[34mEpoch: 27, Loss: 0.582428583077022\u001b[0m\n",
      "\u001b[34mEpoch: 28, Loss: 0.5865284374782017\u001b[0m\n",
      "\u001b[34mEpoch: 29, Loss: 0.5752562582492828\u001b[0m\n",
      "\u001b[34mEpoch: 30, Loss: 0.5647799798420498\u001b[0m\n",
      "\u001b[34mEpoch: 31, Loss: 0.585850213255201\u001b[0m\n",
      "\u001b[34mEpoch: 32, Loss: 0.57293472971235\u001b[0m\n",
      "\u001b[34mEpoch: 33, Loss: 0.5456745369093758\u001b[0m\n",
      "\u001b[34mEpoch: 34, Loss: 0.5571760152067456\u001b[0m\n",
      "\u001b[34mEpoch: 35, Loss: 0.5556168683937618\u001b[0m\n",
      "\u001b[34mEpoch: 36, Loss: 0.5497240253857204\u001b[0m\n",
      "\u001b[34mEpoch: 37, Loss: 0.5449247743402209\u001b[0m\n",
      "\u001b[34mEpoch: 38, Loss: 0.5830137857369014\u001b[0m\n",
      "\u001b[34mEpoch: 39, Loss: 0.545572293656213\u001b[0m\n",
      "\u001b[34mEpoch: 40, Loss: 0.5522258239133018\u001b[0m\n",
      "\u001b[34mEpoch: 41, Loss: 0.5504464592252459\u001b[0m\n",
      "\u001b[34mEpoch: 42, Loss: 0.5257886307580131\u001b[0m\n",
      "\u001b[34mEpoch: 43, Loss: 0.5459868950503213\u001b[0m\n",
      "\u001b[34mEpoch: 44, Loss: 0.5360924005508423\u001b[0m\n",
      "\u001b[34mEpoch: 45, Loss: 0.5188300694738116\u001b[0m\n",
      "\u001b[34mEpoch: 46, Loss: 0.4916642095361437\u001b[0m\n",
      "\u001b[34mEpoch: 47, Loss: 0.5022356765610831\u001b[0m\n",
      "\u001b[34mEpoch: 48, Loss: 0.5198271487440381\u001b[0m\n",
      "\u001b[34mEpoch: 49, Loss: 0.49333628160612925\u001b[0m\n",
      "\u001b[34mEpoch: 50, Loss: 0.5001073564801898\u001b[0m\n",
      "\u001b[34mEpoch: 51, Loss: 0.5071341821125576\u001b[0m\n",
      "\u001b[34mEpoch: 52, Loss: 0.4975958211081369\u001b[0m\n",
      "\u001b[34mEpoch: 53, Loss: 0.5119481980800629\u001b[0m\n",
      "\u001b[34mEpoch: 54, Loss: 0.4936955784048353\u001b[0m\n",
      "\u001b[34mEpoch: 55, Loss: 0.48185350213732037\u001b[0m\n",
      "\u001b[34mEpoch: 56, Loss: 0.48463617478098187\u001b[0m\n",
      "\u001b[34mEpoch: 57, Loss: 0.47328492999076843\u001b[0m\n",
      "\u001b[34mEpoch: 58, Loss: 0.4974742957523891\u001b[0m\n",
      "\u001b[34mEpoch: 59, Loss: 0.4754330175263541\u001b[0m\n",
      "\u001b[34mEpoch: 60, Loss: 0.48293512633868624\u001b[0m\n",
      "\u001b[34mEpoch: 61, Loss: 0.4569693846361978\u001b[0m\n",
      "\u001b[34mEpoch: 62, Loss: 0.4564210559640612\u001b[0m\n",
      "\u001b[34mEpoch: 63, Loss: 0.45550093054771423\u001b[0m\n",
      "\u001b[34mEpoch: 64, Loss: 0.4684574433735439\u001b[0m\n",
      "\u001b[34mEpoch: 65, Loss: 0.4516636984688895\u001b[0m\n",
      "\u001b[34mEpoch: 66, Loss: 0.47357283745493206\u001b[0m\n",
      "\u001b[34mEpoch: 67, Loss: 0.443584816796439\u001b[0m\n",
      "\u001b[34mEpoch: 68, Loss: 0.45243888241904123\u001b[0m\n",
      "\u001b[34mEpoch: 69, Loss: 0.4325068082128252\u001b[0m\n",
      "\u001b[34mEpoch: 70, Loss: 0.45862689188548494\u001b[0m\n",
      "\u001b[34mEpoch: 71, Loss: 0.4450465057577406\u001b[0m\n",
      "\u001b[34mEpoch: 72, Loss: 0.4405611072267805\u001b[0m\n",
      "\u001b[34mEpoch: 73, Loss: 0.45341318420001436\u001b[0m\n",
      "\u001b[34mEpoch: 74, Loss: 0.43289189679282053\u001b[0m\n",
      "\u001b[34mEpoch: 75, Loss: 0.45014524459838867\u001b[0m\n",
      "\u001b[34mEpoch: 76, Loss: 0.4280390611716679\u001b[0m\n",
      "\u001b[34mEpoch: 77, Loss: 0.433726613010679\u001b[0m\n",
      "\u001b[34mEpoch: 78, Loss: 0.4212671475751059\u001b[0m\n",
      "\u001b[34mEpoch: 79, Loss: 0.40726140992982046\u001b[0m\n",
      "\u001b[34mEpoch: 80, Loss: 0.4321382854666029\u001b[0m\n",
      "\u001b[34m2020-07-30 08:58:27,950 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-07-30 08:58:37 Uploading - Uploading generated training model\n",
      "2020-07-30 08:58:37 Completed - Training job completed\n",
      "Training seconds: 99\n",
      "Billable seconds: 99\n",
      "CPU times: user 659 ms, sys: 52.9 ms, total: 712 ms\n",
      "Wall time: 5min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Train your estimator on S3 training data\n",
    "estimator.fit({'train': input_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 练习：部署训练过的模型\n",
    "\n",
    "训练之后，部署模型以创建 `predictor`。如果你使用的是 PyTorch 模型，你需要创建一个训练过的 `PyTorchModel`，它会接受训练过的 `<model>.model_data` 作为输入参数，并指向提供的 `source_pytorch/predict.py` 文件作为入口点。\n",
    "\n",
    "为了部署训练过的模型，你需要使用 `<model>.deploy`，它接受两个参数：\n",
    "* **initial_instance_count**：部署实例的数量 (1)。\n",
    "* **instance_type**：部署 SageMaker 实例的类型。\n",
    "\n",
    "注意：如果你遇到实例错误，可能是因为你选择了错误的训练或部署实例类型。建议参考之前的练习代码，看看我们使用了哪种类型的实例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------!CPU times: user 491 ms, sys: 30 ms, total: 521 ms\n",
      "Wall time: 9min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# uncomment, if needed\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "# deploy your model to create a predictor\n",
    "model = PyTorchModel(model_data = estimator.model_data,\n",
    "                        role = role,\n",
    "                        entry_point = 'predict.py',\n",
    "                        source_dir = 'source_pytorch',\n",
    "                        framework_version = '1.0')\n",
    "predictor = model.deploy(initial_instance_count = 1, instance_type = 'ml.t2.medium')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 评估模型\n",
    "\n",
    "模型部署后，你可以将模型应用到测试数据上，看看模型的效果如何。\n",
    "\n",
    "下面提供的单元格会读入测试数据，并假设它存储在本地 `data_dir` 目录下，名称为 `test.csv`。标签和特征是从 `.csv` 文件提取的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0, 0.922279792746114, 0.8207547169811321],\n",
       " [0.7653061224489796, 0.5896551724137931, 0.6217105263157895],\n",
       " [0.8844444444444445, 0.18099547511312214, 0.597457627118644],\n",
       " [0.6190476190476191, 0.04324324324324325, 0.4278350515463917],\n",
       " [0.92, 0.39436619718309857, 0.775],\n",
       " [0.9926739926739928, 0.9739776951672864, 0.9930555555555556],\n",
       " [0.4126984126984127, 0.0, 0.3466666666666667],\n",
       " [0.4626865671641791, 0.0, 0.18932038834951456],\n",
       " [0.5811518324607329, 0.0, 0.24742268041237114],\n",
       " [0.5842105263157895, 0.0, 0.29441624365482233],\n",
       " [0.5663716814159292, 0.0, 0.25833333333333336],\n",
       " [0.4814814814814815, 0.022900763358778626, 0.2789115646258503],\n",
       " [0.6197916666666666, 0.026595744680851064, 0.3415841584158416],\n",
       " [0.9217391304347826, 0.6548672566371682, 0.9294117647058824],\n",
       " [1.0, 0.9224806201550388, 1.0],\n",
       " [0.8615384615384616, 0.06282722513089005, 0.5047169811320755],\n",
       " [0.6261682242990654, 0.22397476340694009, 0.5585585585585585],\n",
       " [1.0, 0.9688715953307392, 0.9966996699669968],\n",
       " [0.3838383838383838, 0.010309278350515464, 0.17874396135265697],\n",
       " [1.0, 0.9446494464944648, 0.8546712802768166],\n",
       " [0.6139240506329114, 0.0, 0.2983425414364641],\n",
       " [0.9727626459143968, 0.8300395256916996, 0.9270833333333334],\n",
       " [0.962809917355372, 0.6890756302521008, 0.9098039215686274],\n",
       " [0.4152542372881356, 0.0, 0.1774193548387097],\n",
       " [0.5321888412017167, 0.017467248908296942, 0.2458333333333333]]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "import os\n",
    "\n",
    "# read in test data, assuming it is stored locally\n",
    "test_data = pd.read_csv(os.path.join(data_dir, \"test.csv\"), header=None, names=None)\n",
    "\n",
    "# labels are in the first column\n",
    "test_y = test_data.iloc[:,0]\n",
    "test_x = test_data.iloc[:,1:].values.tolist()\n",
    "test_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 练习：确定模型的准确率\n",
    "\n",
    "使用部署的 `predictor` 为测试数据预测类别标签。将这些标签与真实标签 `test_y` 进行比较，并计算 0-1 之间的准确率，表示模型分类正确的测试数据所占的比例。你可以使用 [sklearn.metrics](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) 计算准确率。\n",
    "\n",
    "**要通过此项目，你的模型测试准确率应至少达到 90%。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "# First: generate predicted, class labels\n",
    "test_y_preds = predictor.predict(test_x)\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "# test that your model generates the correct number of labels\n",
    "assert len(test_y_preds)==len(test_y), 'Unexpected number of predictions.'\n",
    "print('Test passed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "\n",
      "Predicted class labels: \n",
      "[1 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0]\n",
      "\n",
      "True class labels: \n",
      "[1 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "# Second: calculate the test accuracy\n",
    "accuracy = accuracy_score(test_y,test_y_preds)\n",
    "\n",
    "print(accuracy)\n",
    "\n",
    "\n",
    "## print out the array of predicted and true labels, if you want\n",
    "print('\\nPredicted class labels: ')\n",
    "print(np.array([int(a[0]) for a in test_y_preds.tolist()]))\n",
    "print('\\nTrue class labels: ')\n",
    "print(test_y.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题 1：你的模型生成了多少个假正例和假负例？为何会这样？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**回答：**模型没有产生假正例和假负例，因为这个数据集相对来说比较小。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题 2：你是如何决定要使用什么类型的模型？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**回答：**决定使用的神经网络模型，一是课程学习使用的神经网络模型，神经网络模型能够较好的拟合分类面。具有强大的拟合能力，因此选择的是神经网络模型。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## 练习：清理资源\n",
    "\n",
    "评估完模型后，记得**删除模型端点**。你可以通过调用 `.delete_endpoint()` 删除端点。你需要在此 notebook 中演示端点已删除。你可以从 AWS 控制台删除任何其他资源，并且在下面找到更多关于删除所有资源的说明。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted sagemaker-pytorch-2020-07-30-08-58-58-455\n"
     ]
    }
   ],
   "source": [
    "# uncomment and fill in the line below!\n",
    "# <name_of_deployed_predictor>.delete_endpoint()\n",
    "def delete_endpoint(predictor):\n",
    "        try:\n",
    "            boto3.client('sagemaker').delete_endpoint(EndpointName=predictor.endpoint)\n",
    "            print('Deleted {}'.format(predictor.endpoint))\n",
    "        except:\n",
    "            print('Already deleted: {}'.format(predictor.endpoint))\n",
    "delete_endpoint(predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 删除 S3 存储桶\n",
    "\n",
    "完全训练和测试完模型后，你可以删除整个 S3 存储桶。如果你在训练模型之前删除存储桶，需要重新创建 S3 存储桶并将训练数据再次上传到存储桶中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# deleting bucket, uncomment lines below\n",
    "\n",
    "# bucket_to_delete = boto3.resource('s3').Bucket(bucket)\n",
    "# bucket_to_delete.objects.all().delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 删除所有模型和实例\n",
    "\n",
    "当你完全处理完模型，并且**不**需要重新访问此 notebook，你可以根据[这些说明](https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-cleanup.html)删除所有 SageMaker notebook 实例和模型。在删除此 notebook 实例之前，建议至少下载一个副本并将其保存到本地。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 后续改进建议\n",
    "\n",
    "此项目还有很多改进或扩展方式，可以拓宽你的知识面，或让此项目更独特。下面是一些建议：\n",
    "* 训练分类器预测剽窃类别 (1-3)，而不仅仅是剽窃 (1) 或非剽窃 (0)。\n",
    "* 利用其他更大型的数据集检测此模型能否扩展到其他类型的剽窃行为。\n",
    "* 利用语言或字符级分析寻找不同（及更多）相似性特征。\n",
    "* 编写完整的管道函数，它会接受原文和提交的文本，并将提交的文本分类为剽窃或非剽窃文本。\n",
    "* 使用 API Gateway 和 lambda 函数将模型部署到网络应用上。\n",
    "\n",
    "这些都只是扩展项目的建议。如果你完成了此 notebook 中的所有练习，你已经完成了一个真实的应用，可以提交项目了。棒棒哒！"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
